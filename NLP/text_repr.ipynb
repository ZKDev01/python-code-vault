{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ee6471fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List,Any,Dict,Tuple\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from numpy import ndarray,dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bb502b",
   "metadata": {},
   "source": [
    "# Text Representations\n",
    "\n",
    "La **Representación de Texto** (**Text Representation**) es el proceso de transformar el lenguaje humano, inherentemente no estructurado y simbólico, en una forma estructurada y numérica que pueda ser procesada por algoritmos computacionales. Esta transformación es fundamental en el proceso de entrenamiento de modelos de ML y técnicas de análisis estadístico que operan exclusivamente sobre datos numéricos.\n",
    "\n",
    "**Técnicas Básicas de Representación de Texto**: Bag-of-Words (BoW), TF-IDF, One-Hot Encoding, Bag-of-N-grams(BoN), Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b1d547cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "  \"el gato juega\",\n",
    "  \"el perro corre\",\n",
    "  \"el gato y el perro son amigos\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64066f84",
   "metadata": {},
   "source": [
    "## BoW\n",
    "\n",
    "**Bag-of-Words** (**BoW**) es un modelo de representación de texto que se basa en la frecuencia con la que aparecen las palabras en un documento. Este modelo tiene como problema que no toma en cuenta el orden o contexto de las palabras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b08b8",
   "metadata": {},
   "source": [
    "### Implementación con Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee163395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_vector(text:str, vocab:dict[str,int], unk_handling:bool=False) -> ndarray[tuple[int], dtype[Any]]:\n",
    "  # convertir vocabulario a formato estandarizado si es necesario\n",
    "  if isinstance(vocab, list):\n",
    "    vocab: dict[str,int] = {word:idx for idx, word in enumerate(vocab)}\n",
    "  \n",
    "  # tokenizar el texto\n",
    "  tokens: list[str] = text.split()\n",
    "  \n",
    "  # inicializar vector one-hot\n",
    "  bow_vector: np.ndarray = np.zeros((len(vocab),), dtype=int)\n",
    "  \n",
    "  for token in tokens:\n",
    "    # manejo de palabras desconocidas\n",
    "    if token not in vocab.keys():\n",
    "      if unk_handling: continue # ignorar palabras desconocidas\n",
    "      else: raise ValueError(f\"Token '{token}' no encontrado en el vocabulario.\")\n",
    "    \n",
    "    # actualizar vector one-hot\n",
    "    vector: ndarray[tuple[int], dtype[Any]] = np.zeros((len(vocab),), dtype=int)\n",
    "    idx: int = vocab[token]\n",
    "    vector[idx] = 1\n",
    "    bow_vector += vector\n",
    "  \n",
    "  return bow_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bafa8a0",
   "metadata": {},
   "source": [
    "### Prueba y Comparación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "92bced19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario construido: {'amigos': 0, 'corre': 1, 'el': 2, 'gato': 3, 'juega': 4, 'perro': 5, 'son': 6, 'y': 7}\n",
      "Texto 'el gato juega'\n",
      "[0 0 1 1 1 0 0 0]\n",
      "Texto 'el perro corre'\n",
      "[0 1 1 0 0 1 0 0]\n",
      "Texto 'el gato y el perro son amigos'\n",
      "[1 0 2 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "vocab = get_vocab_from_corpus(texts)\n",
    "print(f\"Vocabulario construido: {vocab}\")\n",
    "\n",
    "for text in texts:\n",
    "  print(f\"Texto '{text}'\")\n",
    "  onehot = get_bow_vector(text, vocab)\n",
    "  print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a55c825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: ['amigos' 'corre' 'el' 'gato' 'juega' 'perro' 'son']\n",
      "[[0 0 1 1 1 0 0]\n",
      " [0 1 1 0 0 1 0]\n",
      " [1 0 2 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Implementación con Scikit-Learn\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "print(f\"Vocabulario: {vectorizer.get_feature_names_out()}\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfd357",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "**One-Hot Encoding** es una técnica de representación de datos que consiste en convertir cada categoría única en un vector binario. Cada posición del vector representa una categoría y el valor 1 indica la presencia de esa categoría, mientras que el valor 0 indica su ausencia.\n",
    "\n",
    "**Representación Matemática**: Dado un vocabulario $V = \\{ w_{1},w_{2},\\dots,w_{n} \\}$ con $n$ términos únicos, cada término $w_{i}$ se representa como un vector $\\overrightarrow{v}_{i} \\in \\{ 0,1 \\}^n$ donde:\n",
    "\n",
    "$$\\overrightarrow{v}_{i}[j] = \\left\\{  \\begin{array}{l}\n",
    "1 & \\text{si } j = i \\\\\n",
    "0 & \\text{en otro caso}\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "A continuación se muestra una implementación con Numpy para realizar One-Hot Encoding y se compara que los resultados sean iguales a los obtenidos por Scikit-Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895080a9",
   "metadata": {},
   "source": [
    "### Implementación de One-Hot Encoding con Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "632d9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehot_vector(text:str, vocab:List[str], unk_handling:bool=False) -> ndarray[tuple[int], dtype[Any]]:\n",
    "  # convertir vocabulario a formato estandarizado si es necesario\n",
    "  if isinstance(vocab, list):\n",
    "    vocab: dict[str,int] = {word:idx for idx, word in enumerate(vocab)}\n",
    "  \n",
    "  # tokenizar el texto\n",
    "  tokens: list[str] = text.split()\n",
    "  \n",
    "  # inicializar vector one-hot\n",
    "  onehot_vector: np.ndarray = np.zeros((len(tokens), len(vocab)), dtype=int)\n",
    "  \n",
    "  for idx, token in enumerate(tokens):\n",
    "    # manejo de palabras desconocidas\n",
    "    if token not in vocab.keys():\n",
    "      if unk_handling: continue # ignorar palabras desconocidas\n",
    "      else: raise ValueError(f\"Token '{token}' no encontrado en el vocabulario.\")\n",
    "    \n",
    "    # actualizar vector one-hot\n",
    "    onehot_vector[idx, vocab[token]] = 1\n",
    "  \n",
    "  return onehot_vector\n",
    "\n",
    "def get_vocab_from_corpus(corpus:List[str]) -> Dict[str,int]:\n",
    "  unique_words: set[str] = set()\n",
    "  for text in corpus:\n",
    "    tokens: List[str] = text.split()\n",
    "    unique_words.update(tokens)\n",
    "    \n",
    "  # ordenar vocabulario para consistencia\n",
    "  vocab: Dict[str,int] = {word:idx for idx, word in enumerate(sorted(list(unique_words)))}\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84216c94",
   "metadata": {},
   "source": [
    "### Implementación con Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36be9a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_sklearn(texts:List[str], mode='document'):\n",
    "  match mode:\n",
    "    case 'document':\n",
    "      # reprensentación a nivel de documento (Bag-of-Words)\n",
    "      vectorizer = CountVectorizer(binary=True)\n",
    "      onehot_matrix = vectorizer.fit_transform(texts).toarray()\n",
    "      vocab = vectorizer.vocabulary_\n",
    "      return onehot_matrix, vocab\n",
    "    case 'word':\n",
    "      # representación a nivel de palabra (One-Hot Encoding)\n",
    "      vocab = { }\n",
    "      idx_flat = []\n",
    "      \n",
    "      for text in texts: \n",
    "        for word in text.split():\n",
    "          vocab[word] = vocab.get(word, len(vocab))\n",
    "          idx_flat.append(vocab[word])\n",
    "      \n",
    "      encoder = OneHotEncoder(categories=[range(len(vocab))], sparse_output=False)\n",
    "      onehot_matrix = encoder.fit_transform(np.array(idx_flat).reshape(-1, 1))\n",
    "      return onehot_matrix, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9559bac4",
   "metadata": {},
   "source": [
    "### Comparación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4f04c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== One-Hot Word Level =====\n",
      "Vocabulario construido: {'amigos': 0, 'corre': 1, 'el': 2, 'gato': 3, 'juega': 4, 'perro': 5, 'son': 6, 'y': 7}\n",
      "Texto 'el gato juega'\n",
      "[[0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0]]\n",
      "Texto 'el perro corre'\n",
      "[[0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0]]\n",
      "Texto 'el gato y el perro son amigos'\n",
      "[[0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1]\n",
      " [0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== One-Hot Word Level =====\")\n",
    "vocab = get_vocab_from_corpus(texts)\n",
    "print(f\"Vocabulario construido: {vocab}\")\n",
    "\n",
    "for text in texts:\n",
    "  print(f\"Texto '{text}'\")\n",
    "  onehot = get_onehot_vector(text, vocab)\n",
    "  print(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4724e45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SKLearn One-Hot Document Level =====\n",
      "Vocabulario construido: {'el': 2, 'gato': 3, 'juega': 4, 'perro': 5, 'corre': 1, 'son': 6, 'amigos': 0}\n",
      "Matriz One-Hot Document-Word\n",
      "[[0 0 1 1 1 0 0]\n",
      " [0 1 1 0 0 1 0]\n",
      " [1 0 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== SKLearn One-Hot Document Level =====\")\n",
    "onehot_doc, vocab_sklearn = onehot_sklearn(texts, mode='document')\n",
    "print(f\"Vocabulario construido: {vocab_sklearn}\")\n",
    "print(\"Matriz One-Hot Document-Word\")\n",
    "print(onehot_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d7ee0e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SKLearn One-Hot Word Level =====\n",
      "Vocabulario construido: {'el': 0, 'gato': 1, 'juega': 2, 'perro': 3, 'corre': 4, 'y': 5, 'son': 6, 'amigos': 7}\n",
      "Matriz One-Hot Word-Level\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"===== SKLearn One-Hot Word Level =====\")\n",
    "onehot_word, vocab_sklearn_word = onehot_sklearn(texts, mode='word')\n",
    "print(f\"Vocabulario construido: {vocab_sklearn_word}\")\n",
    "print(\"Matriz One-Hot Word-Level\")\n",
    "print(onehot_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efd7a8",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "37562fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras únicas: ['amigos' 'corre' 'el' 'gato' 'juega' 'perro' 'son' 'y']\n",
      "Codificación numérica: [0 1 2 3 4 5 6 7]\n",
      "Ejemplo de conversión 'el gato juega':\n",
      "Original: ['el', 'gato', 'juega'] -> Codificado: [2 3 4]\n"
     ]
    }
   ],
   "source": [
    "vocab = \" \".join(texts).split()\n",
    "encoder = LabelEncoder()\n",
    "encoded_words = encoder.fit_transform(vocab)\n",
    "\n",
    "print(f\"Palabras únicas: {encoder.classes_}\")\n",
    "print(f\"Codificación numérica: {np.arange(len(encoder.classes_))}\")\n",
    "print(f\"Ejemplo de conversión '{texts[0]}':\")\n",
    "words = texts[0].split()\n",
    "encoded_words = encoder.transform(words)\n",
    "print(f\"Original: {words} -> Codificado: {encoded_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9427fa",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a57ecf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario: ['amigos' 'corre' 'el' 'gato' 'juega' 'perro' 'son']\n",
      "[[0.   0.   0.43 0.55 0.72 0.   0.  ]\n",
      " [0.   0.72 0.43 0.   0.   0.55 0.  ]\n",
      " [0.47 0.   0.55 0.36 0.   0.36 0.47]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "print(f\"Vocabulario: {tfidf_vectorizer.get_feature_names_out()}\")\n",
    "print(np.round(X_tfidf.toarray(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a7edeb",
   "metadata": {},
   "source": [
    "## N-Grams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "795f6527",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "  \"No me gusta este producto\",\n",
    "  \"Me gusta mucho este producto\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e5dc70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración: Uni-gramas, Bi-gramas y Tri-gramas\n",
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "X = vectorizer.fit_transform(texts)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df = pd.DataFrame(X.toarray(), columns=feature_names, index=[\"Frase Negativa\",\"Frase Positiva\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "129409d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frase Negativa</th>\n",
       "      <th>Frase Positiva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>este</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>este producto</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gusta</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gusta este</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gusta este producto</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gusta mucho</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gusta mucho este</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me gusta</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me gusta este</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me gusta mucho</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mucho</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mucho este</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mucho este producto</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no me</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no me gusta</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>producto</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Frase Negativa  Frase Positiva\n",
       "este                              1               1\n",
       "este producto                     1               1\n",
       "gusta                             1               1\n",
       "gusta este                        1               0\n",
       "gusta este producto               1               0\n",
       "gusta mucho                       0               1\n",
       "gusta mucho este                  0               1\n",
       "me                                1               1\n",
       "me gusta                          1               1\n",
       "me gusta este                     1               0\n",
       "me gusta mucho                    0               1\n",
       "mucho                             0               1\n",
       "mucho este                        0               1\n",
       "mucho este producto               0               1\n",
       "no                                1               0\n",
       "no me                             1               0\n",
       "no me gusta                       1               0\n",
       "producto                          1               1"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se traspone para mejor lectura\n",
    "df.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
