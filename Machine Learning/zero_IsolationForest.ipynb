{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a68522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import time \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb47c03",
   "metadata": {},
   "source": [
    "**Isolation Forest** es un algoritmo no supervisado que detecta anomalías aislado observaciones en árboles binarios aleatorios. Las anomalías (puntos poco comunes) requieren menos divisiones para ser aisladas que los puntos normales. \n",
    "\n",
    "**Atributos del Algoritmo**: \n",
    "- `n_estimators`: número de árboles en el bosque\n",
    "- `max_sample`: número o proporción de muestras para construir cada árbol\n",
    "- `contamination`: proporción esperada de anomalías en el dataset\n",
    "- `random_state`: semilla para reproducibilidad \n",
    "- `forest`: lista de árboles de aislamiento entrenados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe3c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.5772156649  \n",
    "\n",
    "def _c(n):\n",
    "  \"Constante de normalización para el conjunto de tamaño n\"\n",
    "  if n > 2:\n",
    "    H = math.log(n-1) + gamma\n",
    "    return 2 * H - 2 * (n - 1) / n \n",
    "  elif n == 2:\n",
    "    return 1 \n",
    "  else: \n",
    "    return 0 \n",
    "\n",
    "class iTreeNode:\n",
    "  def __init__(self, size=None, split_attr=None, split_value=None, left=None, right=None):\n",
    "    self.size = size                # solo para nodos externos\n",
    "    self.split_attr = split_attr\n",
    "    self.split_value = split_value\n",
    "    self.left = left\n",
    "    self.right = right\n",
    "\n",
    "def build_iTree(X, height=0, max_height=None):\n",
    "  \"\"\"Construye un iTree recursivamente. \n",
    "\n",
    "  Args:\n",
    "    X: subconjunto de datos \n",
    "    height: altura actual. Defaults to 0.\n",
    "    max_height: altura máxima. Si None, se usa ceil(log2(len(X))).\n",
    "  \"\"\"\n",
    "  n = len(X)\n",
    "  if max_height is None:\n",
    "    max_height = int(np.ceil(np.log2(n)))\n",
    "  \n",
    "  # Condición de parada: altura máxima o un solo punto\n",
    "  if height >= max_height or n <= 1:\n",
    "    return iTreeNode(size=n)\n",
    "  \n",
    "  # Seleccionar atributo y valor de corte aleatorios\n",
    "  m = X.shape[1]\n",
    "  q = np.random.randint(0, m)\n",
    "  min_val = X[:, q].min()\n",
    "  max_val = X[:, q].max()\n",
    "  p = np.random.uniform(min_val, max_val)\n",
    "  \n",
    "  # Dividir datos\n",
    "  left_mask = X[:, q] <= p\n",
    "  right_mask = ~left_mask\n",
    "  X_left = X[left_mask]\n",
    "  X_right = X[right_mask]\n",
    "  \n",
    "  # Si alguna división está vacía, crear nodo externo\n",
    "  if len(X_left) == 0 or len(X_right) == 0:\n",
    "    return iTreeNode(size=n)\n",
    "  \n",
    "  # Construir subárboles recursivamente\n",
    "  left_node = build_iTree(X_left, height + 1, max_height)\n",
    "  right_node = build_iTree(X_right, height + 1, max_height)\n",
    "  \n",
    "  return iTreeNode(split_attr=q, split_value=p, left=left_node, right=right_node)\n",
    "\n",
    "def path_length(x, tree, current_length=0):\n",
    "  \"Calcula la longitud de ruta (path length) ajustada para una instancia x en un iTree\"\n",
    "  # Nodo externo\n",
    "  if tree.size is not None:\n",
    "    return current_length + _c(tree.size)\n",
    "  \n",
    "  # Nodo interno: seguir la rama correspondiente\n",
    "  if x[tree.split_attr] <= tree.split_value:\n",
    "    return path_length(x, tree.left, current_length + 1)\n",
    "  else:\n",
    "    return path_length(x, tree.right, current_length + 1)\n",
    "\n",
    "class Zero_IsolationForest:\n",
    "  \"Implementación propia del algoritmo Isolation Forest para detección de anomalías.\"\n",
    "  \n",
    "  def __init__(self, n_estimators=100, max_samples=256, contamination=0.1, random_state=None):\n",
    "    self.n_estimators = n_estimators\n",
    "    self.max_samples = max_samples\n",
    "    self.contamination = contamination\n",
    "    self.random_state = random_state\n",
    "    self.forest = []\n",
    "    self._subsample_size = None\n",
    "  \n",
    "  def fit(self, X):\n",
    "    np.random.seed(self.random_state)\n",
    "    n = len(X)\n",
    "    self._subsample_size = min(self.max_samples, n) if isinstance(self.max_samples, int) else int(self.max_samples * n)\n",
    "    \n",
    "    self.forest = []\n",
    "    for _ in range(self.n_estimators):\n",
    "      # Submuestreo sin reemplazo\n",
    "      idx = np.random.choice(n, self._subsample_size, replace=False)\n",
    "      X_sub = X[idx]\n",
    "      # Construir iTree\n",
    "      tree = build_iTree(X_sub)\n",
    "      self.forest.append(tree)\n",
    "    return self\n",
    "  \n",
    "  def anomaly_score(self, X):\n",
    "    scores = []\n",
    "    for x in X:\n",
    "      path_lengths = [path_length(x, tree) for tree in self.forest]\n",
    "      avg_path = np.mean(path_lengths)\n",
    "      # Puntuación de anomalía según la fórmula original\n",
    "      score = 2 ** (-avg_path / _c(self._subsample_size))\n",
    "      scores.append(score)\n",
    "    return np.array(scores)\n",
    "  \n",
    "  def predict(self, X):\n",
    "    scores = self.anomaly_score(X)\n",
    "    threshold = np.percentile(scores, 100 * (1 - self.contamination))\n",
    "    return np.where(scores >= threshold, -1, 1)  # -1: anomalía, 1: normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67341248",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data \n",
    "y = iris.target                   # considerar la clase 2 como anomalía\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) \n",
    "y_binary = (y == 2).astype(int)   # 1 para anomalía (clase 2), 0 para normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a091fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "  'n_estimators' : 100, \n",
    "  'contamination': 0.33,\n",
    "  'random_state' : 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fa178",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sk_model = IsolationForest(\n",
    "  n_estimators=params['n_estimators'],\n",
    "  contamination=params['contamination'],\n",
    "  random_state=params['random_state']\n",
    ")\n",
    "sk_model.fit(X_scaled)\n",
    "sk_time = time.time() - start \n",
    "\n",
    "sk_predictions = sk_model.predict(X_scaled)\n",
    "sk_scores = sk_model.decision_function(X_scaled)\n",
    "\n",
    "print(f\"Tiempo de Entrenamiento: {sk_time:.4f}s\")\n",
    "print(f\"Puntuaciones: [{sk_scores.min():.3f}, {sk_scores.max():.3f}]\")\n",
    "print(f\"Media: {sk_scores.mean():.3f}, Desv: {sk_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "zero_model = Zero_IsolationForest(\n",
    "  n_estimators=params['n_estimators'],\n",
    "  contamination=params['contamination'],\n",
    "  random_state=params['random_state']\n",
    ")\n",
    "zero_model.fit(X_scaled)\n",
    "zero_time = time.time() - start \n",
    "\n",
    "zero_predictions = zero_model.predict(X_scaled)\n",
    "zero_scores = zero_model.anomaly_score(X_scaled)\n",
    "\n",
    "print(f\"Tiempo de Entrenamiento: {zero_time:.4f}s\")\n",
    "print(f\"Puntuaciones: [{zero_scores.min():.3f}, {zero_scores.max():.3f}]\")\n",
    "print(f\"Media: {zero_scores.mean():.3f}, Desv: {zero_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba46f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a etiquetas binarias para evaluación\n",
    "sk_labels = (sk_predictions == -1).astype(int)\n",
    "zero_labels = (zero_predictions == -1).astype(int)\n",
    "\n",
    "# Exactitud\n",
    "sk_accuracy = np.mean(sk_labels == y_binary)\n",
    "zero_accuracy = np.mean(zero_labels == y_binary)\n",
    "\n",
    "print(f\"Accuracy (Scikit-Learn Model):    {sk_accuracy:.3f}\")\n",
    "print(f\"Accuracy (Zero Mode):             {zero_accuracy:.3f}\")\n",
    "\n",
    "# Matrices de confusión\n",
    "def print_confusion_matrix(y_true, y_pred, label):\n",
    "  tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "  tn = np.sum((y_true == 0) & (y_pred == 0))\n",
    "  fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "  fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "  \n",
    "  print(f\"Matriz de Confusión ({label})\")\n",
    "  print(f\"                  Predicción\")\n",
    "  print(f\"               Normal  Anomalía\")\n",
    "  print(f\"Real Normal     {tn:3d}      {fp:3d}\")\n",
    "  print(f\"Real Anomalía   {fn:3d}      {tp:3d}\")\n",
    "\n",
    "print_confusion_matrix(y_binary, sk_labels, \"sklearn\")\n",
    "print_confusion_matrix(y_binary, zero_labels, \"zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd758e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Ratio tiempo (propia/sklearn): {zero_time/sk_time:.1f}x\")\n",
    "print(f\"Diferencia en exactitud: {abs(sk_accuracy - zero_accuracy):.3f}\")\n",
    "\n",
    "# Correlación entre puntuaciones (invertir signo de sklearn para comparar)\n",
    "correlation = np.corrcoef(sk_scores, -zero_scores)[0, 1]\n",
    "print(f\"Correlación entre puntuaciones: {correlation:.3f}\")\n",
    "\n",
    "# Puntos con predicciones diferentes\n",
    "diff_predictions = np.sum(sk_labels != zero_labels)\n",
    "print(f\"Instancias con predicciones diferentes: {diff_predictions}/{len(X)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
