{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381db34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "  classification_report, \n",
    "  confusion_matrix, \n",
    "  roc_auc_score, \n",
    "  accuracy_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci칩n de visualizaci칩n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab0374a",
   "metadata": {},
   "source": [
    "### Aprendizaje Semi-Supervisado con Datos Parcialmente Etiquetados\n",
    "\n",
    "**Breast Cancer Wisconsin Dataset**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target  # 0: maligno, 1: benigno\n",
    "\n",
    "print(f\"\"\"Informaci칩n del Dataset:\n",
    "- Dimensi칩n: {df.shape}\n",
    "- Cantidad de Caracter칤sticas: {df.shape[1]-1}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3229021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci칩n de etiquetas y muestra de los datos\n",
    "display(df['target'].value_counts())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba99628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci칩n del dataset\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7701401d",
   "metadata": {},
   "source": [
    "### Simulaci칩n de Datos Semi-Etiquetados\n",
    "Para simular un escenario semi-supervisado, se va a marcar algunas muestras como no etiquetadas ($-1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # para reproducibilidad\n",
    "\n",
    "# Crear una copia de la variable objetivo original\n",
    "df['target_semi'] = df['target'].copy()\n",
    "\n",
    "# Seleccionar aleatoriamente el 70% de los datos para marcarlos como no etiquetados (-1)\n",
    "n_samples = len(df) \n",
    "n_unlabeled = int(0.7 * n_samples)\n",
    "unlabeled_idx = np.random.choice(df.index, size=n_unlabeled, replace=False)\n",
    "\n",
    "# Marcar estos 칤ndices como no etiquetados\n",
    "df.loc[unlabeled_idx, 'target_semi'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1211618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci칩n de etiquetas en el escenario semi-supervisado\n",
    "label_counts = df['target_semi'].value_counts()\n",
    "display(label_counts)\n",
    "\n",
    "print(f\"\"\"Porcentajes:\n",
    "- Etiquetados (0/1):   {100 * (1 - 0.7):.1f}%\n",
    "- No Etiquetados (-1): {100 * 0.7:.1f}%\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0201c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos etiquetados y no etiquetados\n",
    "labeled_mask = df['target_semi'] != -1\n",
    "unlabeled_mask = df['target_semi'] == -1\n",
    "\n",
    "df_labeled = df[labeled_mask].copy()\n",
    "df_unlabeled = df[unlabeled_mask].copy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea712c6",
   "metadata": {},
   "source": [
    "### An치lisis Exploratorio de Datos\n",
    "- Entender la distribuci칩n de los datos\n",
    "- Comparar distribuciones entre datos etiquetados y no etiquetados\n",
    "- Analizar correlaciones entre caracter칤sticas\n",
    "- Visualizar distribuciones por clase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c6a16",
   "metadata": {},
   "source": [
    "#### Distribuci칩n de Clases y An치lisis de Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b70d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. Distribuci칩n de clases en datos etiquetados\n",
    "class_counts = df_labeled['target'].value_counts().sort_index()\n",
    "axes[0].bar(['Maligno (0)', 'Benigno (1)'], class_counts.values, color=['#e74c3c', '#2ecc71'])\n",
    "axes[0].set_title('Distribuci칩n de Clases en Datos Etiquetados', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Cantidad de Muestras', fontsize=12)\n",
    "axes[0].set_xlabel('Clase', fontsize=12)\n",
    "\n",
    "# A침adir etiquetas con los valores\n",
    "for i, v in enumerate(class_counts.values):\n",
    "  axes[0].text(i, v + 3, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 2. Proporci칩n de datos etiquetados vs no etiquetados\n",
    "total_samples = len(df)\n",
    "labeled_pct = len(df_labeled) / total_samples * 100\n",
    "unlabeled_pct = len(df_unlabeled) / total_samples * 100\n",
    "\n",
    "categories = ['Etiquetados', 'No Etiquetados']\n",
    "values = [labeled_pct, unlabeled_pct]\n",
    "colors = ['#3498db', '#f39c12']\n",
    "\n",
    "axes[1].bar(categories, values, color=colors)\n",
    "axes[1].set_title('Proporci칩n de Datos Etiquetados vs No Etiquetados', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Porcentaje (%)', fontsize=12)\n",
    "\n",
    "# A침adir etiquetas con los valores\n",
    "for i, v in enumerate(values):\n",
    "  axes[1].text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb67cc6",
   "metadata": {},
   "source": [
    "#### Comparaci칩n de Distribuciones de las Caracter칤sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797d2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar las caracter칤sticas m치s importantes seg칰n an치lisis previo\n",
    "key_features = [\n",
    "  'worst radius', \n",
    "  'worst texture', \n",
    "  'worst perimeter', \n",
    "  'worst area', \n",
    "  'mean radius', \n",
    "  'mean texture', \n",
    "  'mean perimeter', \n",
    "  'mean area'\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(18, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "  if idx < len(axes):\n",
    "    # Histogramas superpuestos\n",
    "    axes[idx].hist(df_labeled[feature], alpha=0.5, label='Etiquetados', bins=20, color='blue', density=True)\n",
    "    axes[idx].hist(df_unlabeled[feature], alpha=0.5, label='No Etiquetados', bins=20, color='orange', density=True)\n",
    "    axes[idx].set_title(feature.replace('_', ' ').title(), fontsize=10)\n",
    "    axes[idx].set_xlabel('Valor', fontsize=9)\n",
    "    axes[idx].set_ylabel('Densidad', fontsize=9)\n",
    "    \n",
    "    # A침adir estad칤sticas\n",
    "    mean_labeled = df_labeled[feature].mean()\n",
    "    mean_unlabeled = df_unlabeled[feature].mean()\n",
    "    axes[idx].axvline(mean_labeled, color='blue', linestyle='--', linewidth=1, alpha=0.7, label=f'Media Et: {mean_labeled:.1f}')\n",
    "    axes[idx].axvline(mean_unlabeled, color='orange', linestyle='--', linewidth=1, alpha=0.7, label=f'Media NoEt: {mean_unlabeled:.1f}')\n",
    "    \n",
    "    if idx == 0:\n",
    "      axes[idx].legend(fontsize=8, loc='upper right')\n",
    "\n",
    "# Eliminar ejes vac칤os si los hay\n",
    "for idx in range(len(key_features), len(axes)):\n",
    "  fig.delaxes(axes[idx])\n",
    "\n",
    "plt.suptitle('Comparaci칩n de Distribuciones: Etiquetados vs No Etiquetados', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba416bc0",
   "metadata": {},
   "source": [
    "#### Test Estad칤stico de Similitud de Distribuciones (KS Test)\n",
    "\n",
    "**Test Estad칤stico de Kolmogorov-Smirnov** (**KS Test**): Prueba estad칤stica no param칠trica utilizada para comparar distribuciones\n",
    "- *One-Sample KS Test*: Compara una distribuci칩n muestral emp칤rica con una distribuci칩n te칩rica de referencia (normal, exponencial, uniforme, etc.)\n",
    "- *Two-Sample KS Test*: Compara dos distribuciones emp칤ricas para determinar si provienen de la misma distribuci칩n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c702f6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "p_value_selected = 0.05\n",
    "ks_results = []\n",
    "\n",
    "for feature in key_features:\n",
    "  stat, p_value = stats.ks_2samp(df_labeled[feature].dropna(), df_unlabeled[feature].dropna())\n",
    "  ks_results.append({\n",
    "    'Caracter칤stica': feature,\n",
    "    'Estad칤stico KS': stat,\n",
    "    'p-value': p_value,\n",
    "    'Diferencia': 'Significativa' if p_value < p_value_selected else 'No significativa'\n",
    "  })\n",
    "\n",
    "ks_df = pd.DataFrame(ks_results)\n",
    "display(ks_df)\n",
    "print(\"Interpretaci칩n: p-value < 0.05 indica diferencia significativa entre distribuciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e68bcd",
   "metadata": {},
   "source": [
    "#### Matriz de Correlaci칩n Completa y An치lisis de Multicolinealidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869470e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci칩n para todas las caracter칤sticas\n",
    "plt.figure(figsize=(16, 12))\n",
    "corr_matrix = df_labeled[data.feature_names].corr()\n",
    "\n",
    "# Crear m치scara para el tri치ngulo superior\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "# Heatmap de correlaci칩n\n",
    "sns.heatmap(corr_matrix, mask=mask, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=0.5, cbar_kws={\"shrink\": .8},\n",
    "            annot=False, fmt='.2f')\n",
    "\n",
    "plt.title('Matriz de Correlaci칩n Completa - Datos Etiquetados', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc87761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An치lisis de correlaciones\n",
    "threshold = 0.9\n",
    "strong_correlations = []\n",
    "\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "  for j in range(i + 1, len(corr_matrix.columns)):\n",
    "    corr_value = abs(corr_matrix.iloc[i, j])\n",
    "    if corr_value > threshold:\n",
    "      strong_correlations.append({\n",
    "        'Caracter칤stica 1': corr_matrix.columns[i],\n",
    "        'Caracter칤stica 2': corr_matrix.columns[j],\n",
    "        'Correlaci칩n': corr_matrix.iloc[i, j]\n",
    "      })\n",
    "\n",
    "if strong_correlations:\n",
    "  strong_corr_df = pd.DataFrame(strong_correlations)\n",
    "  print(f\"Se encontraron {len(strong_correlations)} pares con correlaci칩n fuerte:\")\n",
    "  print(strong_corr_df.sort_values('Correlaci칩n', ascending=False).to_string(index=False))\n",
    "\n",
    "  # Identificar caracter칤sticas m치s correlacionadas\n",
    "  all_features = list(strong_corr_df['Caracter칤stica 1']) + list(strong_corr_df['Caracter칤stica 2'])\n",
    "  feature_counts = pd.Series(all_features).value_counts()\n",
    "  print(\"Caracter칤sticas m치s frecuentemente correlacionadas:\")\n",
    "  for feature, count in feature_counts.head(5).items():\n",
    "    print(f\"- {feature}: {count} correlaciones fuertes\")\n",
    "else:\n",
    "  print(f\"No se encontraron correlaciones con umbral: > {threshold})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bc92c",
   "metadata": {},
   "source": [
    "#### An치lisis de Outliers y Distribuci칩n por Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar caracter칤sticas m치s relevantes para an치lisis de outliers\n",
    "outlier_features = ['worst radius', 'worst area', 'worst perimeter', 'mean concavity']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(outlier_features):\n",
    "  # Boxplot por clase\n",
    "  sns.boxplot(x='target', y=feature, data=df_labeled, ax=axes[idx],\n",
    "              palette={'0': '#e74c3c', '1': '#2ecc71'})\n",
    "  axes[idx].set_title(f'Distribuci칩n de {feature.replace(\"_\", \" \").title()} por Clase',\n",
    "                      fontsize=12, fontweight='bold')\n",
    "  axes[idx].set_xlabel('Clase (0: Maligno, 1: Benigno)', fontsize=10)\n",
    "  axes[idx].set_ylabel(feature.replace('_', ' ').title(), fontsize=10)\n",
    "\n",
    "  # A침adir estad칤sticas\n",
    "  stats_by_class = df_labeled.groupby('target')[feature].agg(['mean', 'std', 'min', 'max'])\n",
    "  axes[idx].text(0.02, 0.98, f'Media 0: {stats_by_class.loc[0, \"mean\"]:.2f}\\n'\n",
    "                  f'Media 1: {stats_by_class.loc[1, \"mean\"]:.2f}',\n",
    "                  transform=axes[idx].transAxes, fontsize=9,\n",
    "                  verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.suptitle('An치lisis de Outliers y Distribuci칩n por Clase',\n",
    "              fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44461363",
   "metadata": {},
   "source": [
    "#### An치lisis Cuantitativo de Outliers (M칠todo IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99efd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_summary = []\n",
    "for feature in outlier_features:\n",
    "  for target_class in [0, 1]:\n",
    "    subset = df_labeled[df_labeled['target'] == target_class][feature]\n",
    "\n",
    "    # Calcular IQR\n",
    "    Q1 = subset.quantile(0.25)\n",
    "    Q3 = subset.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    # Definir l칤mites\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Contar outliers\n",
    "    outliers = subset[(subset < lower_bound) | (subset > upper_bound)]\n",
    "    outlier_pct = len(outliers) / len(subset) * 100\n",
    "\n",
    "    outlier_summary.append({\n",
    "      'Caracter칤stica': feature,\n",
    "      'Clase': target_class,\n",
    "      'Muestras': len(subset),\n",
    "      'Outliers': len(outliers),\n",
    "      '% Outliers': outlier_pct,\n",
    "      'Q1': Q1,\n",
    "      'Q3': Q3,\n",
    "      'IQR': IQR\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(\"Resumen de outliers por caracter칤stica y clase:\")\n",
    "display(outlier_df[['Caracter칤stica', 'Clase', 'Muestras', 'Outliers', '% Outliers']])\n",
    "\n",
    "# Identificar caracter칤sticas con m치s outliers\n",
    "outlier_by_feature = outlier_df.groupby('Caracter칤stica')['% Outliers'].mean().sort_values(ascending=False)\n",
    "print(\"Caracter칤sticas con mayor porcentaje promedio de outliers:\")\n",
    "for feature, pct in outlier_by_feature.items():\n",
    "  print(f\"- {feature}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labeled[data.feature_names].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002bd875",
   "metadata": {},
   "source": [
    "### Procesamiento de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2313d183",
   "metadata": {},
   "source": [
    "#### Divisi칩n de Datos en Entrenamiento y Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acf2ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled = df_labeled[data.feature_names]\n",
    "y_labeled = df_labeled['target']\n",
    "\n",
    "X_unlabeled = df_unlabeled[data.feature_names]\n",
    "\n",
    "# Dividir datos etiquetados en Entrenamiento y Prueba \n",
    "X_train_labeled, X_test, y_train_labeled, y_test = train_test_split(\n",
    "  X_labeled, \n",
    "  y_labeled, \n",
    "  test_size=0.3, \n",
    "  random_state=42, \n",
    "  stratify=y_labeled\n",
    ")\n",
    "\n",
    "print(f\"\"\"Divisi칩n de Datos:\n",
    "- X_train_labeled: {X_train_labeled.shape}\n",
    "- X_test:          {X_test.shape}\n",
    "- X_unlabeled:     {X_unlabeled.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48040b",
   "metadata": {},
   "source": [
    "#### Normalizaci칩n de Caracter칤sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89230c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_labeled_scaled = scaler.fit_transform(X_train_labeled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_unlabeled_scaled = scaler.transform(X_unlabeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf8324",
   "metadata": {},
   "source": [
    "### Baseline: Modelo Supervisado Tradicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02296b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Regresi칩n Log칤stica\n",
    "lr_baseline = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_baseline.fit(X_train_labeled_scaled, y_train_labeled)\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_baseline = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_baseline.fit(X_train_labeled_scaled, y_train_labeled)\n",
    "\n",
    "# Evaluar modelos baseline\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "  y_pred = model.predict(X_test)\n",
    "  y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "  print(f\"Evaluaci칩n de {model_name}:\")\n",
    "  print(\"=\" * 50)\n",
    "  print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "  if y_proba is not None:\n",
    "    print(f\"AUC-ROC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "  print(\"Reporte de Clasificaci칩n:\")\n",
    "  print(classification_report(y_test, y_pred, target_names=['Maligno', 'Benigno']))\n",
    "\n",
    "  # Matriz de confusi칩n\n",
    "  cm = confusion_matrix(y_test, y_pred)\n",
    "  plt.figure(figsize=(6, 5))\n",
    "  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "              xticklabels=['Maligno', 'Benigno'],\n",
    "              yticklabels=['Maligno', 'Benigno'])\n",
    "  plt.title(f'Matriz de Confusi칩n - {model_name}')\n",
    "  plt.ylabel('Verdadero')\n",
    "  plt.xlabel('Predicho')\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "  return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Evaluar ambos modelos baseline\n",
    "lr_acc = evaluate_model(lr_baseline, X_test_scaled, y_test, \"Logistic Regression Baseline\")\n",
    "rf_acc = evaluate_model(rf_baseline, X_test_scaled, y_test, \"Random Forest Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bd7d0e",
   "metadata": {},
   "source": [
    "### Aprendizaje Semi-Supervisado: Self-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "print(\"\\n游꿢 MODELO SEMI-SUPERVISADO: Self-Training\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Usar Logistic Regression como clasificador base para Self-Training\n",
    "base_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Crear modelo de Self-Training\n",
    "self_training_model = SelfTrainingClassifier(\n",
    "  base_classifier,\n",
    "  # Umbral de confianza para etiquetar datos no etiquetados\n",
    "  threshold=0.75,\n",
    "  # Usar umbral de confianza\n",
    "  criterion='threshold',\n",
    "  # Seleccionar las 10 mejores muestras en cada iteraci칩n\n",
    "  k_best=10,\n",
    "  # M치ximo de iteraciones\n",
    "  max_iter=50,\n",
    ")\n",
    "\n",
    "# Combinar datos etiquetados y no etiquetados\n",
    "# Para aplicar Self-Training, es necesario un array con -1 para datos no etiquetados\n",
    "y_semi = np.concatenate([\n",
    "  y_train_labeled,                      # Etiquetas conocidas\n",
    "  np.full(len(X_unlabeled_scaled), -1)  # -1 para no etiquetados\n",
    "])\n",
    "\n",
    "X_semi = np.vstack([X_train_labeled_scaled, X_unlabeled_scaled])\n",
    "\n",
    "print(f\"\"\"Datos para Self-Training\n",
    "- Total de muestras:       {len(X_semi)}\n",
    "- Muestras etiquetadas:    {len(y_train_labeled)}\n",
    "- Muestras no etiquetadas: {len(X_unlabeled_scaled)}\"\"\")\n",
    "\n",
    "# Entrenar modelo semi-supervisado\n",
    "self_training_model.fit(X_semi, y_semi)\n",
    "\n",
    "# Evaluar el modelo\n",
    "self_train_acc = evaluate_model(\n",
    "  self_training_model,\n",
    "  X_test_scaled,\n",
    "  y_test,\n",
    "  \"Self-Training Semi-Supervised\"\n",
    ")\n",
    "\n",
    "print(f\"\"\"M칠tricas del Self-Training:\n",
    "- N칰mero de Iteraciones Locales:    {self_training_model.n_iter_}\n",
    "- Rango de Iteraciones por Muestra: [{self_training_model.labeled_iter_.min()}, {self_training_model.labeled_iter_.max()}]\n",
    "\n",
    "An치lisis del Proceso de Pseudo-Etiquetado:\n",
    "- Muestras Etiquetadas Originalmente:   {(self_training_model.labeled_iter_ == 0).sum()}\n",
    "- Muestras Etiquetadas Autom치ticamente: {(self_training_model.labeled_iter_ > 0).sum()}\n",
    "- Muestras que no fueron Etiquetadas:   {(self_training_model.labeled_iter_ == -1).sum()}\n",
    "- Condici칩n de Parada:                  {self_training_model.termination_condition_}\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65937d",
   "metadata": {},
   "source": [
    "### Aprendizaje Semi-Supervisado: Label Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e817f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "\n",
    "# Crear y entrenar modelo de Label Propagation\n",
    "label_prop = LabelPropagation(\n",
    "  kernel='rbf', \n",
    "  gamma=0.1, \n",
    "  max_iter=1000, \n",
    "  n_neighbors=7\n",
    ")\n",
    "\n",
    "label_prop.fit(X_semi, y_semi)\n",
    "\n",
    "# Evaluar el modelo\n",
    "label_prop_acc = evaluate_model(\n",
    "  label_prop, \n",
    "  X_test_scaled, \n",
    "  y_test, \n",
    "  \"Label Propagation\"\n",
    ")\n",
    "\n",
    "# Obtener las etiquetas predichas para todos los datos\n",
    "all_labels = label_prop.transduction_\n",
    "\n",
    "print(f\"Distribuci칩n de etiquetas despu칠s de Label Propagation:\")\n",
    "unique, counts = np.unique(all_labels, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "  print(f\"- Clase {label}: {count} muestras ({100*count/len(all_labels):.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ac96a",
   "metadata": {},
   "source": [
    "### Comparaci칩n con Todos los Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3187e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla comparativa\n",
    "results = pd.DataFrame({\n",
    "  'Modelo': [\n",
    "    'Logistic Regression (Baseline)', \n",
    "    'Random Forest (Baseline)',\n",
    "    'Self-Training (Semi-Supervised)',\n",
    "    'Label Propagation (Semi-Supervised)'\n",
    "  ],\n",
    "  'Accuracy': [lr_acc, rf_acc, self_train_acc, label_prop_acc]\n",
    "})\n",
    "\n",
    "results = results.sort_values('Accuracy', ascending=False)\n",
    "results['Mejora vs Baseline'] = results['Accuracy'] - lr_acc\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci칩n comparativa\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(results['Modelo'], results['Accuracy'], color=['#2E86AB', '#A23B72', '#F18F01', '#C73E1D'])\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_title('Comparaci칩n de Modelos: Supervisado vs Semi-Supervisado')\n",
    "ax.set_xlim([0.8, 1.0])\n",
    "\n",
    "# A침adir valores en las barras\n",
    "for bar, acc in zip(bars, results['Accuracy']):\n",
    "  width = bar.get_width()\n",
    "  ax.text(width + 0.005, bar.get_y() + bar.get_height()/2, f'{acc:.4f}', ha='left', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88d7ad4",
   "metadata": {},
   "source": [
    "### An치lisis de Predicciones en Datos No-Etiquetados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir Etiquetas para datos originalmente No Etiquetados\n",
    "unlabeled_predictions_st = self_training_model.predict(X_unlabeled_scaled)\n",
    "unlabeled_predictions_lp = label_prop.predict(X_unlabeled_scaled)\n",
    "\n",
    "# Distribuci칩n de Predicciones\n",
    "print(\"Distribuci칩n de predicciones para datos originalmente no etiquetados:\")\n",
    "print(f\"{'Modelo':<30} {'Clase 0':<10} {'Clase 1':<10}\")\n",
    "\n",
    "for name, preds in [('Self-Training', unlabeled_predictions_st), ('Label Propagation', unlabeled_predictions_lp)]:\n",
    "  unique, counts = np.unique(preds, return_counts=True)\n",
    "  counts_dict = dict(zip(unique, counts))\n",
    "  class0 = counts_dict.get(0, 0)\n",
    "  class1 = counts_dict.get(1, 0)\n",
    "  print(f\"{name:<30} {class0:<10} {class1:<10}\")\n",
    "\n",
    "# An치lisis de Consistencia entre Modelos\n",
    "print(\"\\nConsistencia entre modelos:\")\n",
    "consistency = np.mean(unlabeled_predictions_st == unlabeled_predictions_lp)\n",
    "print(f\"- Porcentaje de acuerdo entre Self-Training y Label Propagation: {100 * consistency:.2f}%\")\n",
    "\n",
    "# An치lisis de Confianza\n",
    "if hasattr(self_training_model, 'predict_proba'):\n",
    "  probas_st = self_training_model.predict_proba(X_unlabeled_scaled)\n",
    "  confidence_st = np.max(probas_st, axis=1)\n",
    "\n",
    "  print(f\"\\nAn치lisis de confianza (Self-Training):\")\n",
    "  print(f\"- Confianza promedio: {confidence_st.mean():.4f}\")\n",
    "  print(f\"- Confianza m칤nima:   {confidence_st.min():.4f}\")\n",
    "  print(f\"- Confianza m치xima:   {confidence_st.max():.4f}\")\n",
    "\n",
    "  # Visualizaci칩n de distribuci칩n de confianza\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  plt.hist(confidence_st, bins=20, alpha=0.7, color='#2E86AB', edgecolor='black')\n",
    "  plt.axvline(x=0.75, color='red', linestyle='--', label='Umbral de Self-Training (0.75)')\n",
    "  plt.xlabel('Confianza de Predicci칩n')\n",
    "  plt.ylabel('Frecuencia')\n",
    "  plt.title('Distribuci칩n de Confianza en Predicciones (Self-Training)')\n",
    "  plt.legend()\n",
    "  plt.grid(True, alpha=0.3)\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
