{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837ff699",
   "metadata": {},
   "source": [
    "### Algoritmo de Clustering: K-Means\n",
    "\n",
    "**K-Means** es un *algoritmo de aprendizaje no-supervisado* utilizado para resolver problemas de *clustering*. Su objetivo es particionar un conjunto de datos en $K$ grupos, llamados *clusters*, donde cada plato pertenece al cluster cuyo *centroide* (el punto medio del cluster) es más cercano. El algoritmo funciona iterativamente para asignar cada punto de datos a uno de los $K$ clusters basándose en las características que los hacen similares, minimizando la varianza intra-cluster.\n",
    "\n",
    "--- \n",
    "\n",
    "Dado un conjunto de datos $X = \\{ \\mathbf{x}_{i} \\}_{i=1}^n$ donde cada $\\mathbf{x}_{i} \\in \\mathbb{R}^d$, y un número entero $k$ que representa la cantidad de clusters a formar, el objetivo de K-Means es encontrar una partición $C = \\{ C_{j} \\}_{j = 1}^k$ que minimice una métrica como **Función de Distorsión**: \n",
    "$$J(C, \\mu) = \\sum_{i=1}^{n} \\|x^{(i)} - \\mu_{C^{(i)}}\\|^2$$\n",
    "donde:\n",
    "- $C_{j}:$ $j$-ésimo cluster\n",
    "- $\\mu_{j}:$ centroide (vector de medias) del cluster $C_{j}$\n",
    "- $|| \\mathbf{x} - \\mu_{j} ||:$ representa la **Distancia Euclidiana** entre el punto $\\mathbf{x}$ y el centroide $\\mu_{j}$\n",
    "\n",
    "La Función de Distorsión $J$ mide la suma de las distancias al cuadrado entre cada ejemplo de entrenamiento $x^{(i)}$ y el centroide de cluster $\\mu_{C^{(i)}}$ al que ha sido asignado. \n",
    "\n",
    "---\n",
    "\n",
    "La función $J$ es una función no convexa, por lo que el descenso coordenado sobre $J$ no está garantizado que converja al mínimo global. En otras palabras, K-Means puede ser susceptible a óptimos locales. Muy a menudo K-Means funcionará bien y producirá agrupamientos muy buenos a pesar de esto. \n",
    "\n",
    "Una alternativa y una práctica común es ejecutar K-Means muchas veces y usando diferentes valores iniciales aleatorios para los centroides de cluster ($\\mu_j$). Luego, de entre todos los diferentes agrupamientos encontrados, elegir el que da la distorsión más baja $J(C, \\mu)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b135101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from IPython.display import display\n",
    "from sklearn import metrics \n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a611f6ee",
   "metadata": {},
   "source": [
    "#### Generación del Dataset y Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c0d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_blobs(\n",
    "  n_samples=5000, \n",
    "  n_features=2, \n",
    "  centers=3, \n",
    "  random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.6, edgecolors='w', linewidth=0.5)\n",
    "plt.xlabel('Característica 1')\n",
    "plt.ylabel('Característica 2')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259830a",
   "metadata": {},
   "source": [
    "#### Aplicación de K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186fbc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "  n_clusters=3,\n",
    "  n_init=3,\n",
    "  init='random',\n",
    "  tol=1e-4, \n",
    "  random_state=42,\n",
    "  verbose=False\n",
    ")\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a977237",
   "metadata": {},
   "source": [
    "**Resultados del Entrenamiento**:\n",
    "- `labels_`: vector con los clusters a los cuales pertenece cada instancia de entrenamiento\n",
    "- `cluster_centers_`: matriz con los centroides de cada grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2ce938",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_kmeans = kmeans.predict(X) \n",
    "centroids = kmeans.cluster_centers_\n",
    "display(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "# Datos\n",
    "plt.scatter(\n",
    "  X[:, 0], X[:, 1], \n",
    "  c=kmeans.labels_, \n",
    "  cmap='viridis', \n",
    "  alpha=0.6, \n",
    "  s=40,\n",
    "  edgecolors='black',\n",
    "  linewidth=0.5\n",
    ")\n",
    "# Centroides\n",
    "plt.scatter(\n",
    "  kmeans.cluster_centers_[:, 0], \n",
    "  kmeans.cluster_centers_[:, 1], \n",
    "  c='red', \n",
    "  marker='X', \n",
    "  s=300,\n",
    "  linewidths=3,\n",
    "  edgecolors='black',\n",
    "  label='Centroides'\n",
    ")\n",
    "plt.title(f'Clustering K-Means (k={kmeans.n_clusters})', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Característica 1')\n",
    "plt.ylabel('Característica 2')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.colorbar(label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf64c75d",
   "metadata": {},
   "source": [
    "#### Métricas de Evaluación\n",
    "Dado que se tienen métricas reales, se pueden calcular algunas métricas: `silhouette_score` y `adjusted_rand_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f89607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "# Silhouette Score: mide la calidad de los clusters, sin necesidad de etiquetas reales\n",
    "sil_score = silhouette_score(X, y_kmeans)\n",
    "print(f\"Silhouette Score: {sil_score:.3f}\")\n",
    "\n",
    "# Adjusted Rand Index: compara con las etiquetas reales\n",
    "ari = adjusted_rand_score(y, y_kmeans)\n",
    "print(f\"Adjusted Rand Index: {ari:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb39288",
   "metadata": {},
   "source": [
    "#### Ejemplo de K-Means con Diferentes Parámetros "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c5c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_k4 = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "kmeans_k4.fit(X)\n",
    "y_kmeans_k4 = kmeans_k4.predict(X)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans_k4, cmap='viridis', s=50, alpha=0.7, edgecolors='k')\n",
    "plt.scatter(kmeans_k4.cluster_centers_[:, 0], kmeans_k4.cluster_centers_[:, 1], \n",
    "            c='red', marker='X', s=200, label='Centroides (k=4)')\n",
    "plt.title('K-Means con k=4')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster predicho')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Calcular inercia (suma de distancias al cuadrado)\n",
    "print(f\"Inercia (k=3): {kmeans.inertia_:.2f}\")\n",
    "print(f\"Inercia (k=4): {kmeans_k4.inertia_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68075391",
   "metadata": {},
   "source": [
    "#### Solución para Elegir K Óptimo\n",
    "**Elbow Method**: Técnica heurística utilizada para determinar el número óptimo de clusters ($k$) en algoritmos de clustering como K-Means. Este método se basa en la idea de que a medida que se aumenta el número de clusters ($k$), la inercia (función de distorsión) disminuye. \n",
    "- Cuando $k$ es muy pequeño, cada vez que aumentamos $k$, la inercia disminuye significativamente\n",
    "- Cuando $k$ se acerca al número óptimo real de clusters, la mejora (reducción de inercia) se vuelve menos pronunciada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80659093",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "K = range(1, 11)\n",
    "for k in K:\n",
    "  kmeans_model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "  kmeans_model.fit(X)\n",
    "  inertias.append(kmeans_model.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, inertias, 'bo-')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('Inercia')\n",
    "plt.title('Método para Determinar K Óptimo')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857c9027",
   "metadata": {},
   "source": [
    "### K-Means desde Cero (K-Means from Scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be688c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansFromScratch:\n",
    "  \"\"\"Implementación del algoritmo K-Means desde cero.\n",
    "\n",
    "  Parámetros:\n",
    "  -----------\n",
    "  n_clusters : int, default=3\n",
    "    Número de clusters a formar.\n",
    "  max_iters : int, default=100\n",
    "    Número máximo de iteraciones.\n",
    "  tol : float, default=1e-4\n",
    "    Tolerancia para declarar convergencia (cambio en inercia).\n",
    "  random_state : int, default=None\n",
    "    Semilla para reproducibilidad.\n",
    "  init_method : str, default='random'\n",
    "    Método de inicialización: 'random' o 'k-means++'.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, n_clusters=3, max_iters=100, tol=1e-4,\n",
    "               random_state=None, init_method='random'):\n",
    "    self.n_clusters = n_clusters\n",
    "    self.max_iters = max_iters\n",
    "    self.tol = tol\n",
    "    self.random_state = random_state\n",
    "    self.init_method = init_method\n",
    "    self.centroids = None\n",
    "    self.labels = None\n",
    "    self.inertia = None\n",
    "    self.history = []  # Para guardar historial de inercia\n",
    "\n",
    "  def _initialize_centroids(self, X):\n",
    "    \"Inicializa los centroides usando el método especificado\"\n",
    "    np.random.seed(self.random_state)\n",
    "    n_samples = X.shape[0]\n",
    "\n",
    "    if self.init_method == 'random':\n",
    "      # Seleccionar k puntos aleatorios del dataset\n",
    "      indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
    "      centroids = X[indices]\n",
    "\n",
    "    elif self.init_method == 'k-means++':\n",
    "      # Método k-means++ para una mejor inicialización\n",
    "      centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "\n",
    "      # Paso 1: Elegir el primer centroide aleatoriamente\n",
    "      first_idx = np.random.randint(n_samples)\n",
    "      centroids[0] = X[first_idx]\n",
    "\n",
    "      # Paso 2: Para cada centroide restante\n",
    "      for i in range(1, self.n_clusters):\n",
    "        # Calcular distancias mínimas al centroide más cercano\n",
    "        distances = np.zeros(n_samples)\n",
    "        for j in range(n_samples):\n",
    "          # Distancia del punto j a todos los centroides existentes\n",
    "          dist_to_centroids = np.linalg.norm(X[j] - centroids[:i], axis=1)\n",
    "          distances[j] = np.min(dist_to_centroids)**2\n",
    "\n",
    "        # Probabilidad proporcional al cuadrado de la distancia\n",
    "        probabilities = distances / distances.sum()\n",
    "\n",
    "        # Elegir nuevo centroide basado en las probabilidades\n",
    "        new_idx = np.random.choice(n_samples, p=probabilities)\n",
    "        centroids[i] = X[new_idx]\n",
    "\n",
    "    return centroids\n",
    "\n",
    "  def _compute_distances(self, X, centroids):\n",
    "    \"\"\"Calcula la distancia entre cada punto y cada centroide\n",
    "\n",
    "    Args:\n",
    "      X: (n_samples, n_features)\n",
    "      centroids: (n_clusters, n_features)\n",
    "\n",
    "    Returns: (n_samples, n_clusters)\n",
    "    \"\"\"\n",
    "    distances = np.zeros((X.shape[0], self.n_clusters))\n",
    "    for i, centroid in enumerate(centroids):\n",
    "      # Distancia euclidiana al cuadrado\n",
    "      distances[:, i] = np.sum((X - centroid)**2, axis=1)\n",
    "\n",
    "    return distances\n",
    "\n",
    "  def _assign_clusters(self, X):\n",
    "    \"Asigna cada punto al cluster más cercano\"\n",
    "    distances = self._compute_distances(X, self.centroids)\n",
    "    # Asignar al cluster con distancia mínima\n",
    "    return np.argmin(distances, axis=1)\n",
    "\n",
    "  def _update_centroids(self, X, labels):\n",
    "    \"Actualiza los centroides como la media de los puntos en cada cluster\"\n",
    "    new_centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
    "\n",
    "    for i in range(self.n_clusters):\n",
    "      # Filtrar puntos que pertenecen al cluster i\n",
    "      cluster_points = X[labels == i]\n",
    "\n",
    "      if len(cluster_points) > 0:\n",
    "        new_centroids[i] = np.mean(cluster_points, axis=0)\n",
    "      else:\n",
    "        # Si un cluster queda vacío, reinicializar su centroide aleatoriamente\n",
    "        new_centroids[i] = X[np.random.randint(X.shape[0])]\n",
    "\n",
    "    return new_centroids\n",
    "\n",
    "  def _compute_inertia(self, X, labels):\n",
    "    \"Calcula la inercia (suma de distancias al cuadrado a los centroides)\"\n",
    "    inertia = 0.0\n",
    "    for i in range(self.n_clusters):\n",
    "      cluster_points = X[labels == i]\n",
    "      if len(cluster_points) > 0:\n",
    "        distances = np.sum((cluster_points - self.centroids[i])**2)\n",
    "        inertia += distances\n",
    "    return inertia\n",
    "\n",
    "  def fit(self, X):\n",
    "    \"\"\"Entrena el modelo K-Means con los datos X.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "      Datos de entrenamiento.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    self : Modelo entrenado.\n",
    "    \"\"\"\n",
    "    # Verificar que X es un array numpy\n",
    "    X = np.array(X)\n",
    "\n",
    "    # Inicializar centroides\n",
    "    self.centroids = self._initialize_centroids(X)\n",
    "\n",
    "    # Bucle principal del algoritmo\n",
    "    for iteration in range(self.max_iters):\n",
    "      # Paso 1: Asignar clusters\n",
    "      self.labels = self._assign_clusters(X)\n",
    "\n",
    "      # Paso 2: Actualizar centroides\n",
    "      new_centroids = self._update_centroids(X, self.labels)\n",
    "\n",
    "      # Paso 3: Calcular inercia\n",
    "      self.inertia = self._compute_inertia(X, self.labels)\n",
    "      self.history.append(self.inertia)\n",
    "\n",
    "      # Paso 4: Verificar convergencia\n",
    "      centroids_change = np.linalg.norm(new_centroids - self.centroids)\n",
    "\n",
    "      if centroids_change < self.tol:\n",
    "        print(f\"Convergió en la iteración {iteration + 1}\")\n",
    "        break\n",
    "\n",
    "      # Actualizar centroides para la siguiente iteración\n",
    "      self.centroids = new_centroids\n",
    "\n",
    "      # Mostrar progreso cada 10 iteraciones\n",
    "      if (iteration + 1) % 10 == 0:\n",
    "        print(f\"Iteración {iteration + 1}, Inercia: {self.inertia:.4f}\")\n",
    "\n",
    "    print(f\"Algoritmo finalizado. Inercia final: {self.inertia:.4f}\")\n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"Predice los clusters para nuevos datos.\n",
    "\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "      Nuevos datos.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    labels : array, shape (n_samples,)\n",
    "      Etiquetas de cluster para cada punto.\n",
    "    \"\"\"\n",
    "    X = np.array(X)\n",
    "    return self._assign_clusters(X)\n",
    "\n",
    "  def fit_predict(self, X):\n",
    "    \"Equivalente a fit() seguido de predict().\"\n",
    "    self.fit(X)\n",
    "    return self.labels\n",
    "\n",
    "  def get_params(self):\n",
    "    \"Retorna los parámetros del modelo.\"\n",
    "    return {\n",
    "      'n_clusters': self.n_clusters,\n",
    "      'max_iters': self.max_iters,\n",
    "      'tol': self.tol,\n",
    "      'random_state': self.random_state,\n",
    "      'init_method': self.init_method\n",
    "    }\n",
    "\n",
    "  def score(self, X):\n",
    "    \"Retorna la inercia negativa (para compatibilidad con GridSearch).\"\n",
    "    if self.centroids is None:\n",
    "      raise ValueError(\"El modelo debe ser entrenado primero.\")\n",
    "    return -self._compute_inertia(X, self.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae8c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar el modelo\n",
    "kmeans_custom = KMeansFromScratch(\n",
    "  n_clusters=3,\n",
    "  max_iters=100,\n",
    "  tol=1e-4,\n",
    "  random_state=42,\n",
    "  init_method='k-means++'\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "labels_custom = kmeans_custom.fit_predict(X)\n",
    "\n",
    "# Visualizar resultados\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Subplot 1: Datos originales\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.title('Datos Originales con Clusters Reales')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster real')\n",
    "\n",
    "# Subplot 2: Resultados de K-Means personalizado\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels_custom, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.scatter(kmeans_custom.centroids[:, 0], kmeans_custom.centroids[:, 1], \n",
    "            marker='X', s=200, c='red', label='Centroides')\n",
    "plt.title('K-Means Personalizado')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.colorbar(label='Cluster predicho')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 3: Evolución de la inercia\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(1, len(kmeans_custom.history) + 1), kmeans_custom.history, 'bo-')\n",
    "plt.xlabel('Iteración')\n",
    "plt.ylabel('Inercia')\n",
    "plt.title('Evolución de la Inercia')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar métricas\n",
    "print(f\"Número de iteraciones realizadas: {len(kmeans_custom.history)}\")\n",
    "print(f\"Inercia final: {kmeans_custom.inertia:.4f}\")\n",
    "print(f\"Centroides finales:\\n{kmeans_custom.centroids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b96ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar K-Means de scikit-learn para comparar\n",
    "kmeans_sklearn = KMeans(n_clusters=3, random_state=42, init='k-means++')\n",
    "labels_sklearn = kmeans_sklearn.fit_predict(X)\n",
    "\n",
    "# Comparar resultados\n",
    "print(\"=\"*50)\n",
    "print(\"COMPARACIÓN CON SCIKIT-LEARN\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nCentroides (Personalizado):\\n{kmeans_custom.centroids}\")\n",
    "print(f\"\\nCentroides (Scikit-learn):\\n{kmeans_sklearn.cluster_centers_}\")\n",
    "\n",
    "print(f\"\\nInercia (Personalizado): {kmeans_custom.inertia:.4f}\")\n",
    "print(f\"Inercia (Scikit-learn): {kmeans_sklearn.inertia_:.4f}\")\n",
    "\n",
    "ari = adjusted_rand_score(labels_sklearn, labels_custom)\n",
    "print(f\"\\nAdjusted Rand Score (similitud): {ari:.4f}\")\n",
    "\n",
    "# Visualizar comparación\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels_custom, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.scatter(kmeans_custom.centroids[:, 0], kmeans_custom.centroids[:, 1], \n",
    "            marker='X', s=200, c='red', label='Centroides')\n",
    "plt.title('K-Means Personalizado')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels_sklearn, cmap='viridis', s=50, alpha=0.7)\n",
    "plt.scatter(kmeans_sklearn.cluster_centers_[:, 0], kmeans_sklearn.cluster_centers_[:, 1], \n",
    "            marker='X', s=200, c='red', label='Centroides')\n",
    "plt.title('K-Means Scikit-learn')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probar con diferentes números de clusters\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "k_values = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for idx, k in enumerate(k_values):\n",
    "  ax = axes[idx // 3, idx % 3]\n",
    "\n",
    "  # Entrenar modelo\n",
    "  kmeans_test = KMeansFromScratch(\n",
    "      n_clusters=k,\n",
    "      max_iters=100,\n",
    "      random_state=42,\n",
    "      init_method='k-means++'\n",
    "  )\n",
    "  labels_test = kmeans_test.fit_predict(X)\n",
    "\n",
    "  # Visualizar\n",
    "  ax.scatter(X[:, 0], X[:, 1], c=labels_test, cmap='viridis', s=30, alpha=0.6)\n",
    "  ax.scatter(kmeans_test.centroids[:, 0], kmeans_test.centroids[:, 1],\n",
    "             marker='X', s=150, c='red', label=f'k={k}')\n",
    "  ax.set_title(f'K-Means con k={k}\\nInercia: {kmeans_test.inertia:.2f}')\n",
    "  ax.set_xlabel('Feature 1')\n",
    "  ax.set_ylabel('Feature 2')\n",
    "  ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
