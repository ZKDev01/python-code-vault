{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8fc93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from typing import List \n",
    "from sklearn.preprocessing import (\n",
    "  LabelEncoder, \n",
    "  StandardScaler\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "  train_test_split,\n",
    "  GridSearchCV, \n",
    "  StratifiedKFold\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "  classification_report,\n",
    "  accuracy_score,\n",
    "  precision_score,\n",
    "  recall_score,\n",
    "  f1_score,\n",
    "  confusion_matrix,\n",
    "  roc_auc_score,\n",
    "  roc_curve\n",
    ")\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Modelos \n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "PATH = \"../_data/healthcare_dataset_stroke_data/healthcare-dataset-stroke-data.csv\"\n",
    "\n",
    "# semilla para reproducibilidad; None para aleatoriedad completa\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bbce3b",
   "metadata": {},
   "source": [
    "## Stroke Prediction Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00590c3b",
   "metadata": {},
   "source": [
    "**Descargar el siguiente dataset**: [Link](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)\n",
    "\n",
    "**Características del Dataset**:\n",
    "\n",
    "- `id`: identificador único\n",
    "- `gender`: \"Male\", \"Female\" u \"Other\"\n",
    "- `age`: edad del paciente\n",
    "- `hypertension`: 0 si el paciente no tiene hipertensión, 1 si el paciente tiene hipertensión\n",
    "- `heart_disease`: 0 si el paciente no tiene enfermedades cardíacas, 1 si el paciente tiene una enfermedad cardíaca\n",
    "- `ever_married`: \"Yes\" o \"No\"\n",
    "- `work_type`: \"children\", \"Govt_jov\", \"Never_worked\", \"Private\" o \"Self-employed\"\n",
    "- `residence_type`: \"Rural\" o \"Urban\"\n",
    "- `avg_glucose_level`: nivel promedio de glucosa en sangre\n",
    "- `bmi`: índice de masa corporal\n",
    "- `smoking_status`: \"formerly smoked\", \"never smoked\", \"smokes\" o \"Unknown\"\n",
    "- `stroke`: 1 si el paciente tuvo un ACV o 0 si no\n",
    "\n",
    "**Objetivo**: Predecir si es probable que un paciente tenga un ataque al corazón (stroke)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2537a6",
   "metadata": {},
   "source": [
    "### Preprocesamiento del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = [ 'gender', 'smoking_status', 'residence_type', 'work_type' ]\n",
    "\n",
    "df = pd.read_csv(PATH)\n",
    "df.columns = df.columns.str.lower() \n",
    "\n",
    "df[\"ever_married\"] = df[\"ever_married\"].map({\"Yes\": True, \"No\": False})\n",
    "\n",
    "for name_feature in category_features:\n",
    "  df[name_feature] = df[name_feature].astype('category')\n",
    "\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee31ce14",
   "metadata": {},
   "source": [
    "Ahora, se va a codificar las variables categóricas que están representadas como cadenas de texto usando el encoder `LabelEncoder`, que codifica las cadenas de texto como números. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0823c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_feature in category_features:\n",
    "  encoder = LabelEncoder()\n",
    "  df[name_feature] = encoder.fit_transform(df[name_feature])\n",
    "\n",
    "display(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cefb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_features = [ \n",
    "  'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
    "  'smoking_status', 'residence_type', 'work_type', 'stroke'\n",
    "]\n",
    "for column in category_features:\n",
    "  display(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f87a23",
   "metadata": {},
   "source": [
    "Se tiene un dataset altamente desbalanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a6f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para separar características de la variable objetivo\n",
    "def get_Xy(df:pd.DataFrame, target:str):\n",
    "  X = df.drop(columns=[target])\n",
    "  y = df[target]\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe54683",
   "metadata": {},
   "source": [
    "### Análisis Exploratorio de Datos\n",
    "\n",
    "El **Análisis Exploratorio de Datos** (EDA) es una fase donde se examinan y se comprende la estructura, características y relaciones subyacentes en un dataset. Este proceso permite:\n",
    "- *Comprensión estructural*: Evaluar dimensiones, tipos de datos y distribuciones para guiar la preparación de datos.\n",
    "- *Identificación de relaciones*: Descubrir patrones, tendencias y correlaciones entre variables\n",
    "- *Detección de anomalías*: Reconocer valores atípicos, datos faltantes o inconsistencias\n",
    "- *Información para modelado*: Fundamentar decisiones sobre transformaciones, ingeniería de características y selección de algoritmos.\n",
    "\n",
    "Esta exploración sistemática establece las bases para un pipeline de ML robusto y con resultados interpretables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Distribución de la Variable Target \n",
    "sns.countplot(data=df, x='stroke', ax=axes[0,0])\n",
    "axes[0,0].set_title('Distribución de Strokes')\n",
    "\n",
    "# Age vs Stroke\n",
    "sns.boxplot(data=df, x='stroke', y='age', ax=axes[0,1])\n",
    "axes[0,1].set_title('Edad vs Stroke')\n",
    "\n",
    "# Avg Glucose Level vs Stroke\n",
    "sns.violinplot(data=df, x='stroke', y='avg_glucose_level', ax=axes[0,2])\n",
    "axes[0,2].set_title('Glucosa vs Stroke')\n",
    "\n",
    "# BMI vs. Stroke\n",
    "sns.boxplot(data=df, x='stroke', y='bmi', ax=axes[1,0])\n",
    "axes[1,0].set_title('BMI vs Stroke')\n",
    "\n",
    "# Gender vs. Stroke\n",
    "sns.countplot(data=df, x='gender', hue='stroke', ax=axes[1,1])\n",
    "axes[1,1].set_title('Género vs Stroke')\n",
    "\n",
    "# Work-Type vs. Stroke\n",
    "sns.countplot(data=df, x='work_type', hue='stroke', ax=axes[1,2])\n",
    "axes[1,2].tick_params(axis='x')\n",
    "axes[1,2].set_title('Trabajo vs Stroke')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38af9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number]).drop(columns=['id'])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(numeric_df.corr(), dtype=bool))\n",
    "\n",
    "sns.heatmap(numeric_df.corr(), mask=mask, annot=True, cmap='RdBu', fmt=\".2f\")\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8241a10",
   "metadata": {},
   "source": [
    "### Clasificación usando Diferentes Modelos\n",
    "\n",
    "En un conjunto de datos desbalanceado, la Exactitud (Accuracy) es engañosa, ya que el modelo puede obtener una puntuación alta simplemente prediciendo siempre la clase mayoritaria. Por lo que se sugiere para este dataset usar AUC (Area Under the Curve), la cual es una medida de la habilidad del clasificador para distinguir entre las clases y se usa como una representación de la curva ROC. Cuando mayor sea el AUC, mejor será el rendimiento del modelo para distinguir entre las clases positivas y negativas. Una curva ROC (Receiver Operating Characteristic Curve) es un gráfico que muestra el rendimiento de un modelo de clasificación en todos los umbrales de clasificación.\n",
    "\n",
    "**Modelos Propuestos**: SVM (Support Vector Machine), Gaussian Naive Bayes, K-Neighbors, Decision Tree, Random Forest, Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008cb1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_Xy(df, target='stroke')\n",
    "display(X.head(10))\n",
    "display(f\"Dimensión de Y: {y.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9dcefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# división del dataset en entrenamiento y prueba \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  X, y, test_size=0.2, random_state=random_state, stratify=y\n",
    ")\n",
    "\n",
    "# información de las particiones\n",
    "print(f\"Dimensión de X_train: {X_train.shape}\")\n",
    "print(f\"Dimensión de X_test: {X_test.shape}\")\n",
    "print(f\"Dimensión de y_train: {y_train.shape}\")\n",
    "print(f\"Dimensión de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61eb097",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Un **Baseline** es un modelo de referencia simple que sirve como punto de comparación mínimo para evaluar modelos más complejos. Este modelo permite:\n",
    "- Establecer un mínimo de rendimiento que cualquier modelo puede superar.\n",
    "- Detectar problemas en los datos o en la métrica de evaluación.\n",
    "- Medir el valor agregado de modelos más complejos. \n",
    "\n",
    "Algunos de los tipos comunes de baselines son: *clase mayoritaria* (siempre predice la clase más frecuente), *clase minoritaria* (siempre predice la clase menos frecuente), *clase aleatoria* (predice aleatoriamente según la distribución de clases) y *clase constante* (siempre predice un valor fijo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c403ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_negative_baseline(y_train, X_test, y_test):\n",
    "  \"Baseline que siempre predice la clase negativa\"\n",
    "  # Siempre predecir 0 para todas las muestras\n",
    "  y_pred_baseline = np.zeros(len(y_test), dtype=int)\n",
    "  # Para AUC se necesitan probabilidades (0% de probabilidad de stroke)\n",
    "  y_pred_proba_baseline = np.zeros(len(y_test))\n",
    "  \n",
    "  # Calcular métricas\n",
    "  accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "  auc_roc = roc_auc_score(y_test, y_pred_proba_baseline)\n",
    "  \n",
    "  return accurancy, auc_roc, y_pred_baseline\n",
    "\n",
    "accuracy_baseline, auc_roc_baseline, y_pred_baseline = create_negative_baseline(y_train, X_test, y_test)\n",
    "print(f\"Baseline - Accuracy: {accuracy_baseline:.4f} | AUC-ROC: {auc_roc_baseline:.4f}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación de Baseline usando DummyClassifier \n",
    "baseline_negative = DummyClassifier(strategy='constant', constant=0)\n",
    "baseline_negative.fit(X_train, y_train) # Se entrena, pero solo \"aprende\" a predecir 0\n",
    "\n",
    "# Predicciones \n",
    "y_pred_baseline = baseline_negative.predict(X_test)\n",
    "# Para AUC se necesitan probabilidades\n",
    "y_pred_proba_baseline = baseline_negative.predict_proba(X_test)[:, 1]\n",
    "# Calcular métricas\n",
    "accuracy_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "auc_roc_baseline = roc_auc_score(y_test, y_pred_proba_baseline)\n",
    "\n",
    "print(f\"DummyClassifier Baseline - Accuracy: {accuracy_baseline:.4f} | AUC-ROC: {auc_roc_baseline:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17911a12",
   "metadata": {},
   "source": [
    "#### Modelo: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a7f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definición del Pipeline para SVM\n",
    "svm_pipeline = Pipeline([\n",
    "  ('scaler', StandardScaler()), \n",
    "  ('SVM', SVC(random_state=random_state, probability=True))\n",
    "])\n",
    "# 2. Parámetros para Búsqueda de Hiperparámetros\n",
    "param_grid = {\n",
    "  'SVM__C': [0.1, 1, 10],              # Parámetro de regularización\n",
    "  'SVM__kernel': ['rbf','linear'],          # Tipos de kernel\n",
    "  'SVM__gamma': ['scale', 'auto'],          # Parámetro gamma para kernel RBF\n",
    "  'SVM__class_weight': ['balanced']         # Manejo de clases desbalanceadas\n",
    "}\n",
    "# 3. Entrenamiento con Validación Cruzada \n",
    "## Usando StratifiedKFold para mantener proporción de clases en cada fold\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Búsqueda de Hiperparámetros con GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "  estimator = svm_pipeline,\n",
    "  param_grid = param_grid,\n",
    "  cv = cv, \n",
    "  scoring = 'roc_auc',          # uso de AUC-ROC por el desbalance de clases\n",
    "  verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2605d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de la Búsqueda de Hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "for key, value in best_params.items():\n",
    "  print(f\"{key}: {value}\")\n",
    "print(f\"Mejor score de validación (AUC-ROC): {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "# Hacer predicciones\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "# Calcular métricas de evaluación\n",
    "accurancy = accuracy_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accurancy:.4f} | AUC-ROC: {auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa3d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función útil para evaluar cualquier modelo \n",
    "def evaluate_model(model, X_test, y_test):\n",
    "  \"Evalúa un modelo y retorna las métricas principales\"\n",
    "  # Predicciones \n",
    "  y_pred = model.predict(X_test)\n",
    "  \n",
    "  # Obtener probabilidades si el modelo las soporta \n",
    "  if hasattr(model, 'predict_proba'):\n",
    "    y_predic_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auc_roc = roc_auc_score(y_test, y_predic_proba)\n",
    "  else:\n",
    "    auc_roc = None\n",
    "  \n",
    "  # Calcular métricas\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "  recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "  f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "  \n",
    "  return {\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1_score': f1,\n",
    "    'auc_roc': auc_roc\n",
    "  }\n",
    "#display(evaluate_model(best_model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "FPR, TPR, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(FPR, TPR, color='blue', label='Curva ROC')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Clasificador Aleatorio')\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC del Modelo SVM')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64282570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confusión \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "  xticklabels=['No Stroke', 'Stroke'], \n",
    "  yticklabels=['No Stroke', 'Stroke'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
